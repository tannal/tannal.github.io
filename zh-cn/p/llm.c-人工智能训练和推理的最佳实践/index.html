<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="ç›®å½• å¼•è¨€ Pytorchç‰ˆæœ¬çš„GPT2 æ¨¡å‹å®ç° Flash æ³¨æ„åŠ› æ··åˆç²¾åº¦ è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ– å‰å‘ä¼ æ’­ åå‘ä¼ æ’­ è‡ªåŠ¨å¾®åˆ† æ¢¯åº¦æ›´æ–° ç³»ç»Ÿçº§ä¼˜åŒ– å†…å­˜ç®¡ç† CUDAåç«¯ å•æœºå¤šå¡ å¤šæœºå¤šå¡ LLama3: å±•æœ›æœªæ¥ ç»“è®º 1. å¼•è¨€ å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²ç»æˆä¸ºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„é‡è¦çªç ´ã€‚éšç€æ¨¡å‹è§„æ¨¡çš„ä¸æ–­æ‰©å¤§å’Œæ¶æ„çš„æ—¥ç›Šå¤æ‚ï¼Œè®­ç»ƒå’Œæ¨ç†è¿™äº›æ¨¡å‹æ‰€é¢ä¸´çš„æŒ‘æˆ˜ä¹Ÿéšä¹‹å¢åŠ ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨å®ç°é«˜æ•ˆLLMè®­ç»ƒå’Œæ¨ç†çš„æœ€ä½³å®è·µï¼Œä»¥GPT2ä¸ºä¾‹ï¼Œå¹¶æ¶µç›–ä»æ¨¡å‹å®ç°åˆ°ç³»ç»Ÿçº§ä¼˜åŒ–çš„å„ä¸ªæ–¹é¢ã€‚\n2. Pytorchç‰ˆæœ¬çš„GPT2 GPT2ä½œä¸ºä¸€ä¸ªé‡Œç¨‹ç¢‘å¼çš„è¯­è¨€æ¨¡å‹ï¼Œå…¶Pytorchå®ç°åŒ…å«äº†è®¸å¤šå€¼å¾—æ·±å…¥ç ”ç©¶çš„æŠ€æœ¯ç»†èŠ‚ã€‚\n2.1 æ¨¡å‹å®ç° GPT2çš„æ ¸å¿ƒæ˜¯Transformeræ¶æ„ï¼Œå…·ä½“åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªå…³é”®ç»„ä»¶ï¼š\nåµŒå…¥å±‚ï¼š\nå®ç°ï¼šä½¿ç”¨nn.Embeddingæ¥å°†è¾“å…¥tokenè½¬æ¢ä¸ºå¯†é›†å‘é‡è¡¨ç¤ºã€‚ æœ€ä½³å®è·µï¼š self.wte = nn.Embedding(vocab_size, n_embd) self.wpe = nn.Embedding(block_size, n_embd) æ³¨æ„äº‹é¡¹ï¼šç¡®ä¿åµŒå…¥ç»´åº¦ä¸æ¨¡å‹å…¶ä»–éƒ¨åˆ†ä¸€è‡´ã€‚ å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼š\nå®ç°ï¼šä½¿ç”¨nn.Linearå±‚å®ç°æŸ¥è¯¢ã€é”®ã€å€¼çš„è½¬æ¢ï¼Œç„¶åè¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚ æœ€ä½³å®è·µï¼š class SelfAttention(nn.Module): def __init__(self, n_embd, n_head): super().__init__() self.c_attn = nn.Linear(n_embd, 3 * n_embd) self.c_proj = nn.Linear(n_embd, n_embd) self.n_head = n_head self.n_embd = n_embd def forward(self, x): B, T, C = x.size() q, k, v = self.c_attn(x).split(self.n_embd, dim=2) k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1))) att = F.softmax(att, dim=-1) y = att @ v y = y.transpose(1, 2).contiguous().view(B, T, C) return self.c_proj(y) æ³¨æ„äº‹é¡¹ï¼šæ³¨æ„åŠ›æƒé‡çš„ç¼©æ”¾å› å­å¾ˆé‡è¦ï¼Œé€šå¸¸ä½¿ç”¨1/sqrt(d_k)ã€‚ å‰é¦ˆç½‘ç»œï¼š\n"><title>LLM.C äººå·¥æ™ºèƒ½è®­ç»ƒå’Œæ¨ç†çš„æœ€ä½³å®è·µ</title><link rel=canonical href=https://tannal.github.io/zh-cn/p/llm.c-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%AE%AD%E7%BB%83%E5%92%8C%E6%8E%A8%E7%90%86%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/><link rel=stylesheet href=/scss/style.min.b0e76e98cdd4f7082d1fc36f7af7e0843a81201db2197c03ca426751dc923735.css><meta property='og:title' content="LLM.C äººå·¥æ™ºèƒ½è®­ç»ƒå’Œæ¨ç†çš„æœ€ä½³å®è·µ"><meta property='og:description' content="ç›®å½• å¼•è¨€ Pytorchç‰ˆæœ¬çš„GPT2 æ¨¡å‹å®ç° Flash æ³¨æ„åŠ› æ··åˆç²¾åº¦ è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ– å‰å‘ä¼ æ’­ åå‘ä¼ æ’­ è‡ªåŠ¨å¾®åˆ† æ¢¯åº¦æ›´æ–° ç³»ç»Ÿçº§ä¼˜åŒ– å†…å­˜ç®¡ç† CUDAåç«¯ å•æœºå¤šå¡ å¤šæœºå¤šå¡ LLama3: å±•æœ›æœªæ¥ ç»“è®º 1. å¼•è¨€ å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²ç»æˆä¸ºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„é‡è¦çªç ´ã€‚éšç€æ¨¡å‹è§„æ¨¡çš„ä¸æ–­æ‰©å¤§å’Œæ¶æ„çš„æ—¥ç›Šå¤æ‚ï¼Œè®­ç»ƒå’Œæ¨ç†è¿™äº›æ¨¡å‹æ‰€é¢ä¸´çš„æŒ‘æˆ˜ä¹Ÿéšä¹‹å¢åŠ ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨å®ç°é«˜æ•ˆLLMè®­ç»ƒå’Œæ¨ç†çš„æœ€ä½³å®è·µï¼Œä»¥GPT2ä¸ºä¾‹ï¼Œå¹¶æ¶µç›–ä»æ¨¡å‹å®ç°åˆ°ç³»ç»Ÿçº§ä¼˜åŒ–çš„å„ä¸ªæ–¹é¢ã€‚\n2. Pytorchç‰ˆæœ¬çš„GPT2 GPT2ä½œä¸ºä¸€ä¸ªé‡Œç¨‹ç¢‘å¼çš„è¯­è¨€æ¨¡å‹ï¼Œå…¶Pytorchå®ç°åŒ…å«äº†è®¸å¤šå€¼å¾—æ·±å…¥ç ”ç©¶çš„æŠ€æœ¯ç»†èŠ‚ã€‚\n2.1 æ¨¡å‹å®ç° GPT2çš„æ ¸å¿ƒæ˜¯Transformeræ¶æ„ï¼Œå…·ä½“åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªå…³é”®ç»„ä»¶ï¼š\nåµŒå…¥å±‚ï¼š\nå®ç°ï¼šä½¿ç”¨nn.Embeddingæ¥å°†è¾“å…¥tokenè½¬æ¢ä¸ºå¯†é›†å‘é‡è¡¨ç¤ºã€‚ æœ€ä½³å®è·µï¼š self.wte = nn.Embedding(vocab_size, n_embd) self.wpe = nn.Embedding(block_size, n_embd) æ³¨æ„äº‹é¡¹ï¼šç¡®ä¿åµŒå…¥ç»´åº¦ä¸æ¨¡å‹å…¶ä»–éƒ¨åˆ†ä¸€è‡´ã€‚ å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼š\nå®ç°ï¼šä½¿ç”¨nn.Linearå±‚å®ç°æŸ¥è¯¢ã€é”®ã€å€¼çš„è½¬æ¢ï¼Œç„¶åè¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚ æœ€ä½³å®è·µï¼š class SelfAttention(nn.Module): def __init__(self, n_embd, n_head): super().__init__() self.c_attn = nn.Linear(n_embd, 3 * n_embd) self.c_proj = nn.Linear(n_embd, n_embd) self.n_head = n_head self.n_embd = n_embd def forward(self, x): B, T, C = x.size() q, k, v = self.c_attn(x).split(self.n_embd, dim=2) k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1))) att = F.softmax(att, dim=-1) y = att @ v y = y.transpose(1, 2).contiguous().view(B, T, C) return self.c_proj(y) æ³¨æ„äº‹é¡¹ï¼šæ³¨æ„åŠ›æƒé‡çš„ç¼©æ”¾å› å­å¾ˆé‡è¦ï¼Œé€šå¸¸ä½¿ç”¨1/sqrt(d_k)ã€‚ å‰é¦ˆç½‘ç»œï¼š\n"><meta property='og:url' content='https://tannal.github.io/zh-cn/p/llm.c-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%AE%AD%E7%BB%83%E5%92%8C%E6%8E%A8%E7%90%86%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/'><meta property='og:site_name' content='è°­ç›Ÿ'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='ç¥ç»ç½‘ç»œ'><meta property='article:published_time' content='2024-10-11T10:51:56+08:00'><meta property='article:modified_time' content='2024-10-11T10:51:56+08:00'><meta name=twitter:title content="LLM.C äººå·¥æ™ºèƒ½è®­ç»ƒå’Œæ¨ç†çš„æœ€ä½³å®è·µ"><meta name=twitter:description content="ç›®å½• å¼•è¨€ Pytorchç‰ˆæœ¬çš„GPT2 æ¨¡å‹å®ç° Flash æ³¨æ„åŠ› æ··åˆç²¾åº¦ è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ– å‰å‘ä¼ æ’­ åå‘ä¼ æ’­ è‡ªåŠ¨å¾®åˆ† æ¢¯åº¦æ›´æ–° ç³»ç»Ÿçº§ä¼˜åŒ– å†…å­˜ç®¡ç† CUDAåç«¯ å•æœºå¤šå¡ å¤šæœºå¤šå¡ LLama3: å±•æœ›æœªæ¥ ç»“è®º 1. å¼•è¨€ å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²ç»æˆä¸ºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„é‡è¦çªç ´ã€‚éšç€æ¨¡å‹è§„æ¨¡çš„ä¸æ–­æ‰©å¤§å’Œæ¶æ„çš„æ—¥ç›Šå¤æ‚ï¼Œè®­ç»ƒå’Œæ¨ç†è¿™äº›æ¨¡å‹æ‰€é¢ä¸´çš„æŒ‘æˆ˜ä¹Ÿéšä¹‹å¢åŠ ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨å®ç°é«˜æ•ˆLLMè®­ç»ƒå’Œæ¨ç†çš„æœ€ä½³å®è·µï¼Œä»¥GPT2ä¸ºä¾‹ï¼Œå¹¶æ¶µç›–ä»æ¨¡å‹å®ç°åˆ°ç³»ç»Ÿçº§ä¼˜åŒ–çš„å„ä¸ªæ–¹é¢ã€‚\n2. Pytorchç‰ˆæœ¬çš„GPT2 GPT2ä½œä¸ºä¸€ä¸ªé‡Œç¨‹ç¢‘å¼çš„è¯­è¨€æ¨¡å‹ï¼Œå…¶Pytorchå®ç°åŒ…å«äº†è®¸å¤šå€¼å¾—æ·±å…¥ç ”ç©¶çš„æŠ€æœ¯ç»†èŠ‚ã€‚\n2.1 æ¨¡å‹å®ç° GPT2çš„æ ¸å¿ƒæ˜¯Transformeræ¶æ„ï¼Œå…·ä½“åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªå…³é”®ç»„ä»¶ï¼š\nåµŒå…¥å±‚ï¼š\nå®ç°ï¼šä½¿ç”¨nn.Embeddingæ¥å°†è¾“å…¥tokenè½¬æ¢ä¸ºå¯†é›†å‘é‡è¡¨ç¤ºã€‚ æœ€ä½³å®è·µï¼š self.wte = nn.Embedding(vocab_size, n_embd) self.wpe = nn.Embedding(block_size, n_embd) æ³¨æ„äº‹é¡¹ï¼šç¡®ä¿åµŒå…¥ç»´åº¦ä¸æ¨¡å‹å…¶ä»–éƒ¨åˆ†ä¸€è‡´ã€‚ å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼š\nå®ç°ï¼šä½¿ç”¨nn.Linearå±‚å®ç°æŸ¥è¯¢ã€é”®ã€å€¼çš„è½¬æ¢ï¼Œç„¶åè¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚ æœ€ä½³å®è·µï¼š class SelfAttention(nn.Module): def __init__(self, n_embd, n_head): super().__init__() self.c_attn = nn.Linear(n_embd, 3 * n_embd) self.c_proj = nn.Linear(n_embd, n_embd) self.n_head = n_head self.n_embd = n_embd def forward(self, x): B, T, C = x.size() q, k, v = self.c_attn(x).split(self.n_embd, dim=2) k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1))) att = F.softmax(att, dim=-1) y = att @ v y = y.transpose(1, 2).contiguous().view(B, T, C) return self.c_proj(y) æ³¨æ„äº‹é¡¹ï¼šæ³¨æ„åŠ›æƒé‡çš„ç¼©æ”¾å› å­å¾ˆé‡è¦ï¼Œé€šå¸¸ä½¿ç”¨1/sqrt(d_k)ã€‚ å‰é¦ˆç½‘ç»œï¼š\n"><link rel="shortcut icon" href=/favicon.ico></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=åˆ‡æ¢èœå•>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/zh-cn/><img src=/img/avatar_hu_23460dfa2f6975f3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>ğŸ¤Ÿ</span></figure><div class=site-meta><h1 class=site-name><a href=/zh-cn>è°­ç›Ÿ</a></h1><h2 class=site-description>stay hungry, stay foolish</h2></div></header><ol class=menu-social><li><a href=https://space.bilibili.com/3546751254399476 target=_blank title="B ç«™ã€Œèµ·ä¸ªåå­—å«çŠŸé©´ã€" rel=me><!doctype html><svg t="1712105268862" class="icon" viewBox="0 0 1024 1024" p-id="5725" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><path d="M1019.54782609 345.3106087c-3.20556522-142.1133913-127.15408696-169.36069565-127.15408696-169.36069566s-96.70121739-.53426087-222.25252174-1.60278261l91.3586087-88.15304347s14.42504348-18.16486957-10.15095652-38.46678261c-24.576-20.30191304-26.17878261-11.21947826-34.72695653-5.87686957-7.47965217 5.3426087-117.00313043 112.72904348-136.23652174 131.96243479-49.68626087.0-101.50956522-.53426087-151.73008695-.53426087h17.63060869S315.392 43.98747826 306.84382609 38.1106087s-9.61669565-14.42504348-34.72695652 5.87686956c-24.576 20.30191304-10.15095652 38.46678261-10.15095653 38.46678261l93.49565218 90.82434783c-101.50956522.0-189.12834783.53426087-229.73217392 2.13704347C-5.69878261 213.34817391 4.45217391 345.3106087 4.45217391 345.3106087s1.60278261 283.15826087.0 426.34017391c14.42504348 143.18191304 124.48278261 166.15513043 124.48278261 166.15513043s43.8093913 1.06852174 76.39930435 1.06852174c3.20556522 9.08243478 5.87686957 53.96034783 56.0973913 53.96034783 49.68626087.0 56.0973913-53.96034783 56.09739131-53.96034783s365.96869565-1.60278261 396.42156522-1.60278261c1.60278261 15.49356522 9.08243478 56.63165217 59.30295652 56.09739131 49.68626087-1.06852174 53.42608696-59.30295652 53.42608695-59.30295652s17.09634783-1.60278261 67.85113044.0c118.60591304-21.90469565 125.55130435-160.81252174 125.55130435-160.81252174s-2.13704348-285.82956522-.53426087-427.94295652zM917.504 798.36382609c0 22.43895652-17.6306087 40.60382609-39.53530435 40.60382608H156.71652174c-21.90469565.0-39.53530435-18.16486957-39.53530435-40.60382608V320.20034783c0-22.43895652 17.6306087-40.60382609 39.53530435-40.60382609h721.25217391c21.90469565.0 39.53530435 18.16486957 39.53530435 40.60382609v478.16347826z" fill="#8a8a8a" p-id="5726"/><path d="M409.088 418.816l-203.264 38.912 17.408 76.288 201.216-38.912zm109.568 202.24c-49.664 106.496-94.208 26.112-94.208 26.112l-33.28 21.504s65.536 89.6 128 21.504c73.728 68.096 130.048-22.016 130.048-22.016l-30.208-19.456c0-.512-52.736 75.776-100.352-27.648zM619.008 495.104l201.728 38.912 16.896-76.288-202.752-38.912z" fill="#8a8a8a" p-id="5727"/></svg></a></li><li><a href=https://github.com/tannal target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://twitter.com/megotannal target=_blank title=Twitter rel=me><svg class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li><li><a href=https://www.zhihu.com/people/roseduan target=_blank title=Zhihu rel=me><!doctype html><svg t="1704259577746" class="icon" viewBox="0 0 1024 1024" p-id="5040" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><path d="M570.581333 806.272h61.952L652.928 876.117333 764.074667 806.272h130.986666V230.186667h-324.48V806.272zM636.501333 292.693333h192.64V743.68h-73.898666l-73.813334 46.378667L668.032 743.808l-31.530667-.128V292.736zM515.754667 493.738667H377.429333a2999.466667 2999.466667.0 005.802667-194.56h135.338667S523.776 239.445334 495.872 240.128H261.76c9.216-34.730667 20.821333-70.613333 34.688-107.690667.0.0-63.701333.0-85.333333 57.130667C202.112 213.12 176.128 303.786667 129.877333 396.416c15.573333-1.706667 67.114667-3.114667 97.450667-58.794667 5.589333-15.616 6.656-17.621333 13.568-38.485333h76.373333c0 27.776-3.157333 177.109333-4.437333 194.474667h-138.24c-31.104.0-41.173333 62.549333-41.173333 62.549333h173.482666C295.253333 688.256 232.789333 799.573333 119.466667 887.466667c54.186667 15.488 108.202667-2.432 134.912-26.197334.0.0 60.8-55.338667 94.122666-183.381333L491.264 849.834667s20.906667-71.168-3.285333-105.856c-20.053333-23.637333-74.24-87.552-97.322667-110.72l-38.698667 30.72c11.52-36.992 18.474667-72.96 20.821334-107.690667h163.072s-.213333-62.549333-20.053334-62.549333z" p-id="5041" fill="#8a8a8a"/></svg></a></li><li><a href=https://mp.weixin.qq.com/s/hs36eiU7Zr-UdJ0YBtZgKQ target=_blank title="å¾®ä¿¡å…¬ä¼—å· roseduanå†™å­—çš„åœ°æ–¹" rel=me><!doctype html><svg t="1704259948565" class="icon" viewBox="0 0 1194 1024" p-id="5272" xmlns:xlink="http://www.w3.org/1999/xlink" width="233.203125" height="200"><path d="M728.064 535.296a35.498667 35.498667.0 11-70.912.0 35.498667 35.498667.0 0170.912.0m246.016.0a35.498667 35.498667.0 11-70.997333.0 35.498667 35.498667.0 0170.997333.0" fill="#8a8a8a" p-id="5273"/><path d="M902.144 930.133333l-6.656 1.450667a594.176 594.176.0 01-18.602667 3.669333c-26.453333 4.778667-44.629333 6.826667-64 6.144C645.034666 935.850666 514.218666 853.504 461.824 722.688a446.464 446.464.0 01-6.826667-19.114667l-1.962666-6.058666a199.68 199.68.0 01-3.84-13.653334 338.858667 338.858667.0 01-9.216-75.690666c0-171.008 157.013333-305.92 354.304-314.709334l8.874666-.682666c7.850667-.597333 12.970667-.853333 18.773334-.853334h14.762666l9.301334.170667c188.16 14.677333 340.394667 156.672 340.394666 323.925333.0 78.336-38.826667 155.733333-109.653333 222.293334a303.530667 303.530667.0 01-7.082667 6.4l9.984 71.082666a49.152 49.152.0 01-69.12 58.453334l-98.816-46.421334a582.485333 582.485333.0 01-9.472 2.304zm220.16-314.026666c0-131.754667-124.586667-247.978667-279.125333-260.096H821.930667c-3.754667.0-7.68.085333-13.994667.597333l-10.666667.768C631.466667 364.8 503.978667 474.453333 503.978667 608.256c0 18.773333 2.730667 40.874667 7.509333 60.842667.597333 2.474667 1.450667 5.632 2.56 9.216l1.706667 4.949333c2.133333 6.570667 4.266667 12.629333 5.632 15.957333 42.325333 105.728 149.930667 173.397333 293.717333 178.176 13.738667.512 28.16-1.109333 50.346667-5.12a531.626667 531.626667.0 0016.64-3.242666l5.632-1.28c4.693333-1.109333 8.448-1.962667 19.370666-4.778667a32 32 0 0121.418667 2.133333L1013.76 905.216l-9.984-69.290667a32 32 0 0113.909333-31.232c1.194667-.853333 8.618667-6.912 15.189334-13.056 58.709333-55.210667 89.429333-116.394667 89.429333-175.616zM12.970667 378.197333C12.970667 171.52 206.677333 5.376 442.709333 5.376c208.384.0 394.24 130.304 431.872 306.090667 1.28 5.973333 1.28 11.264.512 16.896a32 32 0 01-63.658666-5.973334C779.178667 179.2 621.482667 69.376 442.709333 69.376c-202.666666.0-365.738666 139.776-365.738666 308.906667.0 89.941333 46.165333 171.52 136.021333 237.568a32 32 0 0111.434667 35.84l-23.296 69.973333 104.96-48.896a32 32 0 0122.442666-1.706667l5.461334 1.706667c54.357333 11.093333 76.288 14.506667 108.714666 14.506667a200.789333 200.789333.0 0032.256-4.010667c-.512.170667-1.536.512-2.730666 1.536a33.109333 33.109333.0 0139.253333 1.109333A32 32 0 01516.864 730.88c-11.776 14.848-47.36 20.309333-74.24 20.309333-37.12.0-62.037333-3.584-119.893333-15.530666L198.570667 793.6a49.493333 49.493333.0 01-68.949334-59.733333l26.88-80.64c-93.525333-75.52-143.530666-170.24-143.530666-275.029334z" fill="#8a8a8a" p-id="5274"/><path d="M344.576 254.378667a44.373333 44.373333.0 11-88.746667.085333 44.373333 44.373333.0 0188.746667.0M636.586667 254.378667A44.373333 44.373333.0 11547.84 254.464a44.373333 44.373333.0 0188.746667.0" fill="#8a8a8a" p-id="5275"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/zh-cn/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>ä¸»é¡µ</span></a></li><li><a href=/zh-cn/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>å½’æ¡£</span></a></li><li><a href=/zh-cn/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>æœç´¢</span></a></li><li><a href=/zh-cn/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M8 7a4 4 0 108 0A4 4 0 008 7"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>å…³äº</span></a></li><li class=menu-bottom-section><ol class=menu><li id=i18n-switch><svg class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg>
<select name=language title=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://tannal.github.io/>English</option><option value=https://tannal.github.io/zh-cn/ selected>Chinese</option></select></li><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>æš—è‰²æ¨¡å¼</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">ç›®å½•</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#ç›®å½•>ç›®å½•</a></li><li><a href=#1-å¼•è¨€>1. å¼•è¨€</a></li><li><a href=#2-pytorchç‰ˆæœ¬çš„gpt2>2. Pytorchç‰ˆæœ¬çš„GPT2</a><ol><li><a href=#21-æ¨¡å‹å®ç°>2.1 æ¨¡å‹å®ç°</a></li><li><a href=#22-flash-æ³¨æ„åŠ›>2.2 Flash æ³¨æ„åŠ›</a></li><li><a href=#23-æ··åˆç²¾åº¦>2.3 æ··åˆç²¾åº¦</a></li></ol></li><li><a href=#3-è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ–>3. è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ–</a><ol><li><a href=#31-å‰å‘ä¼ æ’­>3.1 å‰å‘ä¼ æ’­</a></li><li><a href=#32-åå‘ä¼ æ’­>3.2 åå‘ä¼ æ’­</a></li><li><a href=#33-è‡ªåŠ¨å¾®åˆ†>3.3 è‡ªåŠ¨å¾®åˆ†</a></li><li><a href=#34-æ¢¯åº¦æ›´æ–°>3.4 æ¢¯åº¦æ›´æ–°</a></li></ol></li><li><a href=#4-ç³»ç»Ÿçº§ä¼˜åŒ–>4. ç³»ç»Ÿçº§ä¼˜åŒ–</a><ol><li><a href=#41-å†…å­˜ç®¡ç†>4.1 å†…å­˜ç®¡ç†</a></li><li><a href=#42-cudaåç«¯>4.2 CUDAåç«¯</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/zh-cn/categories/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>å¤§è¯­è¨€æ¨¡å‹</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/zh-cn/p/llm.c-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%AE%AD%E7%BB%83%E5%92%8C%E6%8E%A8%E7%90%86%E7%9A%84%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/>LLM.C äººå·¥æ™ºèƒ½è®­ç»ƒå’Œæ¨ç†çš„æœ€ä½³å®è·µ</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published datetime=2024-10-11T10:51:56+08:00>Oct 11, 2024</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>é˜…è¯»æ—¶é•¿: 5 åˆ†é’Ÿ</time></div></footer></div></header><section class=article-content><h2 id=ç›®å½•>ç›®å½•</h2><ol><li><a class=link href=#%e5%bc%95%e8%a8%80>å¼•è¨€</a></li><li><a class=link href=#pytorch%e7%89%88%e6%9c%ac%e7%9a%84gpt2>Pytorchç‰ˆæœ¬çš„GPT2</a><ul><li><a class=link href=#%e6%a8%a1%e5%9e%8b%e5%ae%9e%e7%8e%b0>æ¨¡å‹å®ç°</a></li><li><a class=link href=#flash-%e6%b3%a8%e6%84%8f%e5%8a%9b>Flash æ³¨æ„åŠ›</a></li><li><a class=link href=#%e6%b7%b7%e5%90%88%e7%b2%be%e5%ba%a6>æ··åˆç²¾åº¦</a></li></ul></li><li><a class=link href=#%e8%ae%ad%e7%bb%83%e8%bf%87%e7%a8%8b%e4%bc%98%e5%8c%96>è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ–</a><ul><li><a class=link href=#%e5%89%8d%e5%90%91%e4%bc%a0%e6%92%ad>å‰å‘ä¼ æ’­</a></li><li><a class=link href=#%e5%8f%8d%e5%90%91%e4%bc%a0%e6%92%ad>åå‘ä¼ æ’­</a></li><li><a class=link href=#%e8%87%aa%e5%8a%a8%e5%be%ae%e5%88%86>è‡ªåŠ¨å¾®åˆ†</a></li><li><a class=link href=#%e6%a2%af%e5%ba%a6%e6%9b%b4%e6%96%b0>æ¢¯åº¦æ›´æ–°</a></li></ul></li><li><a class=link href=#%e7%b3%bb%e7%bb%9f%e7%ba%a7%e4%bc%98%e5%8c%96>ç³»ç»Ÿçº§ä¼˜åŒ–</a><ul><li><a class=link href=#%e5%86%85%e5%ad%98%e7%ae%a1%e7%90%86>å†…å­˜ç®¡ç†</a></li><li><a class=link href=#cuda%e5%90%8e%e7%ab%af>CUDAåç«¯</a></li><li><a class=link href=#%e5%8d%95%e6%9c%ba%e5%a4%9a%e5%8d%a1>å•æœºå¤šå¡</a></li><li><a class=link href=#%e5%a4%9a%e6%9c%ba%e5%a4%9a%e5%8d%a1>å¤šæœºå¤šå¡</a></li></ul></li><li><a class=link href=#llama3-%e5%b1%95%e6%9c%9b%e6%9c%aa%e6%9d%a5>LLama3: å±•æœ›æœªæ¥</a></li><li><a class=link href=#%e7%bb%93%e8%ae%ba>ç»“è®º</a></li></ol><p><a name=å¼•è¨€></a></p><h2 id=1-å¼•è¨€>1. å¼•è¨€</h2><p>å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²ç»æˆä¸ºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„é‡è¦çªç ´ã€‚éšç€æ¨¡å‹è§„æ¨¡çš„ä¸æ–­æ‰©å¤§å’Œæ¶æ„çš„æ—¥ç›Šå¤æ‚ï¼Œè®­ç»ƒå’Œæ¨ç†è¿™äº›æ¨¡å‹æ‰€é¢ä¸´çš„æŒ‘æˆ˜ä¹Ÿéšä¹‹å¢åŠ ã€‚æœ¬æ–‡å°†æ·±å…¥æ¢è®¨å®ç°é«˜æ•ˆLLMè®­ç»ƒå’Œæ¨ç†çš„æœ€ä½³å®è·µï¼Œä»¥GPT2ä¸ºä¾‹ï¼Œå¹¶æ¶µç›–ä»æ¨¡å‹å®ç°åˆ°ç³»ç»Ÿçº§ä¼˜åŒ–çš„å„ä¸ªæ–¹é¢ã€‚</p><p><a name=pytorchç‰ˆæœ¬çš„gpt2></a></p><h2 id=2-pytorchç‰ˆæœ¬çš„gpt2>2. Pytorchç‰ˆæœ¬çš„GPT2</h2><p>GPT2ä½œä¸ºä¸€ä¸ªé‡Œç¨‹ç¢‘å¼çš„è¯­è¨€æ¨¡å‹ï¼Œå…¶Pytorchå®ç°åŒ…å«äº†è®¸å¤šå€¼å¾—æ·±å…¥ç ”ç©¶çš„æŠ€æœ¯ç»†èŠ‚ã€‚</p><p><a name=æ¨¡å‹å®ç°></a></p><h3 id=21-æ¨¡å‹å®ç°>2.1 æ¨¡å‹å®ç°</h3><p>GPT2çš„æ ¸å¿ƒæ˜¯Transformeræ¶æ„ï¼Œå…·ä½“åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªå…³é”®ç»„ä»¶ï¼š</p><ol><li><p><strong>åµŒå…¥å±‚</strong>ï¼š</p><ul><li>å®ç°ï¼šä½¿ç”¨<code>nn.Embedding</code>æ¥å°†è¾“å…¥tokenè½¬æ¢ä¸ºå¯†é›†å‘é‡è¡¨ç¤ºã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>wte</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>wpe</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>block_size</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šç¡®ä¿åµŒå…¥ç»´åº¦ä¸æ¨¡å‹å…¶ä»–éƒ¨åˆ†ä¸€è‡´ã€‚</li></ul></li><li><p><strong>å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶</strong>ï¼š</p><ul><li>å®ç°ï¼šä½¿ç”¨<code>nn.Linear</code>å±‚å®ç°æŸ¥è¯¢ã€é”®ã€å€¼çš„è½¬æ¢ï¼Œç„¶åè¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>SelfAttention</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>,</span> <span class=n>n_head</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>c_attn</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=mi>3</span> <span class=o>*</span> <span class=n>n_embd</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>c_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>n_head</span> <span class=o>=</span> <span class=n>n_head</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>n_embd</span> <span class=o>=</span> <span class=n>n_embd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>B</span><span class=p>,</span> <span class=n>T</span><span class=p>,</span> <span class=n>C</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>q</span><span class=p>,</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>c_attn</span><span class=p>(</span><span class=n>x</span><span class=p>)</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>k</span> <span class=o>=</span> <span class=n>k</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=n>T</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_head</span><span class=p>,</span> <span class=n>C</span> <span class=o>//</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_head</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>q</span> <span class=o>=</span> <span class=n>q</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=n>T</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_head</span><span class=p>,</span> <span class=n>C</span> <span class=o>//</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_head</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>v</span> <span class=o>=</span> <span class=n>v</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=n>T</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_head</span><span class=p>,</span> <span class=n>C</span> <span class=o>//</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_head</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>att</span> <span class=o>=</span> <span class=p>(</span><span class=n>q</span> <span class=o>@</span> <span class=n>k</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>))</span> <span class=o>*</span> <span class=p>(</span><span class=mf>1.0</span> <span class=o>/</span> <span class=n>math</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>k</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>        <span class=n>att</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>att</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>att</span> <span class=o>@</span> <span class=n>v</span>
</span></span><span class=line><span class=cl>        <span class=n>y</span> <span class=o>=</span> <span class=n>y</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=n>T</span><span class=p>,</span> <span class=n>C</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>c_proj</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šæ³¨æ„åŠ›æƒé‡çš„ç¼©æ”¾å› å­å¾ˆé‡è¦ï¼Œé€šå¸¸ä½¿ç”¨<code>1/sqrt(d_k)</code>ã€‚</li></ul></li><li><p><strong>å‰é¦ˆç½‘ç»œ</strong>ï¼š</p><ul><li>å®ç°ï¼šé€šå¸¸ä½¿ç”¨ä¸¤ä¸ª<code>nn.Linear</code>å±‚ï¼Œä¸­é—´å¸¦æœ‰æ¿€æ´»å‡½æ•°ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>MLP</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>c_fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=mi>4</span> <span class=o>*</span> <span class=n>n_embd</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>c_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>4</span> <span class=o>*</span> <span class=n>n_embd</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>act</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>c_proj</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>act</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>c_fc</span><span class=p>(</span><span class=n>x</span><span class=p>)))</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šä¸­é—´å±‚çš„ç»´åº¦é€šå¸¸æ˜¯è¾“å…¥ç»´åº¦çš„4å€ã€‚</li></ul></li><li><p><strong>å±‚å½’ä¸€åŒ–</strong>ï¼š</p><ul><li>å®ç°ï¼šåœ¨æ¯ä¸ªå­å±‚ä¹‹åä½¿ç”¨<code>nn.LayerNorm</code>ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>ln_1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>ln_2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šç¡®ä¿å½’ä¸€åŒ–åº”ç”¨åœ¨æ®‹å·®è¿æ¥ä¹‹å‰ã€‚</li></ul></li><li><p><strong>ä½ç½®ç¼–ç </strong>ï¼š</p><ul><li>å®ç°ï¼šä½¿ç”¨å¯å­¦ä¹ çš„ä½ç½®åµŒå…¥ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>pos_embedding</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>block_size</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>))</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šè€ƒè™‘ä½¿ç”¨æ­£å¼¦ä½ç½®ç¼–ç ä½œä¸ºåˆå§‹åŒ–ã€‚</li></ul></li><li><p><strong>Transformerå—</strong>ï¼š</p><ul><li>å®ç°ï¼šå°†ä¸Šè¿°ç»„ä»¶ç»„åˆæˆä¸€ä¸ªTransformerå—ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Block</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>,</span> <span class=n>n_head</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>ln_1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>attn</span> <span class=o>=</span> <span class=n>SelfAttention</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>n_head</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>ln_2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>mlp</span> <span class=o>=</span> <span class=n>MLP</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>attn</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>ln_1</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mlp</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>ln_2</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šç¡®ä¿æ®‹å·®è¿æ¥æ­£ç¡®å®ç°ã€‚</li></ul></li><li><p><strong>å®Œæ•´çš„GPT2æ¨¡å‹</strong>ï¼š</p><ul><li>å®ç°ï¼šå°†æ‰€æœ‰ç»„ä»¶ç»„åˆæˆå®Œæ•´çš„GPT2æ¨¡å‹ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>GPT2</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>,</span> <span class=n>n_head</span><span class=p>,</span> <span class=n>n_layer</span><span class=p>,</span> <span class=n>block_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>tok_emb</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>pos_emb</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>block_size</span><span class=p>,</span> <span class=n>n_embd</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>drop</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>blocks</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>([</span><span class=n>Block</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>n_head</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n_layer</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>ln_f</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>n_embd</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>head</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_embd</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>idx</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>b</span><span class=p>,</span> <span class=n>t</span> <span class=o>=</span> <span class=n>idx</span><span class=o>.</span><span class=n>size</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>tok_emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tok_emb</span><span class=p>(</span><span class=n>idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>pos_emb</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pos_emb</span><span class=p>[:,</span> <span class=p>:</span><span class=n>t</span><span class=p>,</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=n>tok_emb</span> <span class=o>+</span> <span class=n>pos_emb</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>block</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>blocks</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>x</span> <span class=o>=</span> <span class=n>block</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>ln_f</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>logits</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>head</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>logits</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šç¡®ä¿æ¨¡å‹å‚æ•°åˆå§‹åŒ–å¾—å½“ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨ç‰¹å®šçš„åˆå§‹åŒ–æ–¹æ³•ã€‚</li></ul></li></ol><p><a name=flash-æ³¨æ„åŠ›></a></p><h3 id=22-flash-æ³¨æ„åŠ›>2.2 Flash æ³¨æ„åŠ›</h3><p>Flash Attentionæ˜¯ä¸€ç§ä¼˜åŒ–æ³¨æ„åŠ›è®¡ç®—çš„æŠ€æœ¯ï¼Œå®ƒå¯ä»¥æ˜¾è‘—å‡å°‘å†…å­˜ä½¿ç”¨å¹¶åŠ é€Ÿè®¡ç®—ã€‚</p><ol><li><p><strong>åŸç†</strong>ï¼š</p><ul><li>Flash Attentioné€šè¿‡é‡ç»„æ³¨æ„åŠ›è®¡ç®—æ¥å‡å°‘å†…å­˜è®¿é—®å’Œæé«˜è®¡ç®—æ•ˆç‡ã€‚</li><li>å®ƒå°†è¾“å…¥åˆ†å‰²æˆæ›´å°çš„å—ï¼Œå¹¶åœ¨è¿™äº›å—ä¸Šæ‰§è¡Œæ³¨æ„åŠ›è®¡ç®—ï¼Œä»è€Œå‡å°‘å†…å­˜ä½¿ç”¨ã€‚</li></ul></li><li><p><strong>å®ç°</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>flash_attention</span><span class=p>(</span><span class=n>q</span><span class=p>,</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span><span class=p>,</span> <span class=n>mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=p>,</span> <span class=n>num_heads</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=n>head_dim</span> <span class=o>=</span> <span class=n>q</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=n>scale</span> <span class=o>=</span> <span class=n>head_dim</span> <span class=o>**</span> <span class=o>-</span><span class=mf>0.5</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># å°†è¾“å…¥é‡å¡‘ä¸º3Då¼ é‡</span>
</span></span><span class=line><span class=cl>    <span class=n>q</span> <span class=o>=</span> <span class=n>q</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>batch_size</span> <span class=o>*</span> <span class=n>seq_len</span><span class=p>,</span> <span class=n>num_heads</span><span class=p>,</span> <span class=n>head_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>k</span> <span class=o>=</span> <span class=n>k</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>batch_size</span> <span class=o>*</span> <span class=n>seq_len</span><span class=p>,</span> <span class=n>num_heads</span><span class=p>,</span> <span class=n>head_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>v</span> <span class=o>=</span> <span class=n>v</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>batch_size</span> <span class=o>*</span> <span class=n>seq_len</span><span class=p>,</span> <span class=n>num_heads</span><span class=p>,</span> <span class=n>head_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>bmm</span><span class=p>(</span><span class=n>q</span><span class=p>,</span> <span class=n>k</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>))</span> <span class=o>*</span> <span class=n>scale</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>mask</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>scores</span> <span class=o>=</span> <span class=n>scores</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>mask</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;-inf&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># åº”ç”¨softmax</span>
</span></span><span class=line><span class=cl>    <span class=n>attn_weights</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>scores</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># è®¡ç®—è¾“å‡º</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>bmm</span><span class=p>(</span><span class=n>attn_weights</span><span class=p>,</span> <span class=n>v</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># é‡å¡‘å›åŸå§‹å½¢çŠ¶</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>output</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>batch_size</span><span class=p>,</span> <span class=n>seq_len</span><span class=p>,</span> <span class=n>num_heads</span><span class=p>,</span> <span class=n>head_dim</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>output</span>
</span></span></code></pre></div></li><li><p><strong>ä¼˜åŒ–æŠ€å·§</strong>ï¼š</p><ul><li>ä½¿ç”¨çŸ©é˜µä¹˜æ³•ï¼ˆ<code>bmm</code>ï¼‰ä»£æ›¿çˆ±å› æ–¯å¦æ±‚å’Œã€‚</li><li>åˆ©ç”¨GPUçš„å…±äº«å†…å­˜æ¥å­˜å‚¨ä¸­é—´ç»“æœã€‚</li><li>ä½¿ç”¨æ··åˆç²¾åº¦è®¡ç®—æ¥è¿›ä¸€æ­¥æé«˜æ•ˆç‡ã€‚</li></ul></li><li><p><strong>æ³¨æ„äº‹é¡¹</strong>ï¼š</p><ul><li>Flash Attentionå¯èƒ½ä¸é€‚ç”¨äºæ‰€æœ‰æƒ…å†µï¼Œç‰¹åˆ«æ˜¯å¯¹äºéå¸¸çŸ­çš„åºåˆ—ã€‚</li><li>åœ¨å®ç°æ—¶éœ€è¦ä»”ç»†å¤„ç†è¾¹ç•Œæƒ…å†µå’Œæ•°å€¼ç¨³å®šæ€§ã€‚</li></ul></li></ol><p><a name=æ··åˆç²¾åº¦></a></p><h3 id=23-æ··åˆç²¾åº¦>2.3 æ··åˆç²¾åº¦</h3><p>æ··åˆç²¾åº¦è®­ç»ƒæ˜¯ä¸€ç§åœ¨ä¿æŒæ¨¡å‹ç²¾åº¦çš„åŒæ—¶æé«˜è®­ç»ƒæ•ˆç‡çš„æŠ€æœ¯ã€‚</p><ol><li><p><strong>åŸç†</strong>ï¼š</p><ul><li>ä½¿ç”¨FP16ï¼ˆåŠç²¾åº¦æµ®ç‚¹æ•°ï¼‰è¿›è¡Œå¤§éƒ¨åˆ†è®¡ç®—ã€‚</li><li>ä½¿ç”¨FP32ï¼ˆå•ç²¾åº¦æµ®ç‚¹æ•°ï¼‰å­˜å‚¨ä¸»è¦å‚æ•°å’Œæ‰§è¡Œå…³é”®æ“ä½œã€‚</li></ul></li><li><p><strong>å®ç°</strong>ï¼š</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.cuda.amp</span> <span class=kn>import</span> <span class=n>autocast</span><span class=p>,</span> <span class=n>GradScaler</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># åˆå§‹åŒ–</span>
</span></span><span class=line><span class=cl><span class=n>scaler</span> <span class=o>=</span> <span class=n>GradScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># è®­ç»ƒå¾ªç¯</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>batch</span> <span class=ow>in</span> <span class=n>dataloader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>autocast</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>batch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>targets</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=o>.</span><span class=n>scale</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>optimizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=o>.</span><span class=n>update</span><span class=p>()</span>
</span></span></code></pre></div></li><li><p><strong>åŠ¨æ€æŸå¤±ç¼©æ”¾</strong>ï¼š</p><ul><li>è‡ªåŠ¨è°ƒæ•´æŸå¤±ç¼©æ”¾å› å­ä»¥é˜²æ­¢æ¢¯åº¦ä¸‹æº¢æˆ–ä¸Šæº¢ã€‚</li><li>PyTorchçš„<code>GradScaler</code>ä¼šè‡ªåŠ¨å¤„ç†è¿™ä¸ªè¿‡ç¨‹ã€‚</li></ul></li><li><p><strong>æœ€ä½³å®è·µ</strong>ï¼š</p><ul><li>å¯¹äºæŸäº›æ“ä½œï¼ˆå¦‚softmaxï¼‰ï¼Œè€ƒè™‘ä½¿ç”¨FP32è®¡ç®—ä»¥ä¿æŒæ•°å€¼ç¨³å®šæ€§ã€‚</li><li>ç›‘æ§è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢¯åº¦å€¼ï¼Œç¡®ä¿å®ƒä»¬ä¸ä¼šå˜ä¸ºNaNæˆ–infã€‚</li><li>åœ¨éªŒè¯å’Œæ¨ç†æ—¶ï¼Œè€ƒè™‘ä½¿ç”¨FP32ä»¥è·å¾—æœ€é«˜ç²¾åº¦ã€‚</li></ul></li><li><p><strong>æ³¨æ„äº‹é¡¹</strong>ï¼š</p><ul><li>å¹¶éæ‰€æœ‰æ“ä½œéƒ½æ”¯æŒFP16ï¼Œéœ€è¦ä»”ç»†æ£€æŸ¥å’Œæµ‹è¯•ã€‚</li><li>æŸäº›æ¨¡å‹æ¶æ„å¯èƒ½å¯¹æ··åˆç²¾åº¦è®­ç»ƒæ›´æ•æ„Ÿï¼Œå¯èƒ½éœ€è¦é¢å¤–çš„è°ƒæ•´ã€‚</li></ul></li></ol><p><a name=è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ–></a></p><h2 id=3-è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ–>3. è®­ç»ƒè¿‡ç¨‹ä¼˜åŒ–</h2><p>ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹å¯¹äºæé«˜LLMçš„è®­ç»ƒæ•ˆç‡è‡³å…³é‡è¦ã€‚è¿™åŒ…æ‹¬å‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ã€è‡ªåŠ¨å¾®åˆ†å’Œæ¢¯åº¦æ›´æ–°ç­‰æ–¹é¢ã€‚</p><p><a name=å‰å‘ä¼ æ’­></a></p><h3 id=31-å‰å‘ä¼ æ’­>3.1 å‰å‘ä¼ æ’­</h3><p>å‰å‘ä¼ æ’­æ˜¯æ¨¡å‹è®¡ç®—è¾“å‡ºçš„è¿‡ç¨‹ï¼Œå¯¹å…¶è¿›è¡Œä¼˜åŒ–å¯ä»¥æ˜¾è‘—æé«˜è®­ç»ƒé€Ÿåº¦ã€‚</p><ol><li><p><strong>æ‰¹å¤„ç†è¾“å…¥åºåˆ—</strong>ï¼š</p><ul><li>å®ç°ï¼šä½¿ç”¨paddingå’Œmaskæ¥å¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>collate_fn</span><span class=p>(</span><span class=n>batch</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># å‡è®¾batchæ˜¯ä¸€ä¸ªåŒ…å«æ–‡æœ¬åºåˆ—çš„åˆ—è¡¨</span>
</span></span><span class=line><span class=cl>    <span class=n>lengths</span> <span class=o>=</span> <span class=p>[</span><span class=nb>len</span><span class=p>(</span><span class=n>seq</span><span class=p>)</span> <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>batch</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>max_len</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>lengths</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>padded</span> <span class=o>=</span> <span class=p>[</span><span class=n>seq</span> <span class=o>+</span> <span class=p>[</span><span class=n>pad_token</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=n>max_len</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>seq</span><span class=p>))</span> <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>batch</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>mask</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>1</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>seq</span><span class=p>)</span> <span class=o>+</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=p>(</span><span class=n>max_len</span> <span class=o>-</span> <span class=nb>len</span><span class=p>(</span><span class=n>seq</span><span class=p>))</span> <span class=k>for</span> <span class=n>seq</span> <span class=ow>in</span> <span class=n>batch</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>LongTensor</span><span class=p>(</span><span class=n>padded</span><span class=p>),</span> <span class=n>torch</span><span class=o>.</span><span class=n>BoolTensor</span><span class=p>(</span><span class=n>mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>dataloader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>collate_fn</span><span class=o>=</span><span class=n>collate_fn</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šç¡®ä¿æ¨¡å‹æ­£ç¡®å¤„ç†paddingå’Œmaskã€‚</li></ul></li><li><p><strong>ç¼“å­˜ä¸­é—´ç»“æœ</strong>ï¼š</p><ul><li>å®ç°ï¼šåœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­å­˜å‚¨ä¸­é—´æ¿€æ´»ï¼Œä»¥ä¾¿åœ¨åå‘ä¼ æ’­æ—¶é‡ç”¨ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>TransformerBlock</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>attention_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>attention</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>intermediate</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>intermediate</span><span class=p>(</span><span class=n>attention_output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>output</span><span class=p>(</span><span class=n>intermediate</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># å­˜å‚¨ä¸­é—´ç»“æœ</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>cached_attention_output</span> <span class=o>=</span> <span class=n>attention_output</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>cached_intermediate</span> <span class=o>=</span> <span class=n>intermediate</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šéœ€è¦åœ¨åå‘ä¼ æ’­åæ¸…é™¤ç¼“å­˜ä»¥èŠ‚çœå†…å­˜ã€‚</li></ul></li><li><p><strong>è®¡ç®—å›¾ä¼˜åŒ–</strong>ï¼š</p><ul><li>ä½¿ç”¨PyTorchçš„JITï¼ˆJust-In-Timeï¼‰ç¼–è¯‘æ¥ä¼˜åŒ–è®¡ç®—å›¾ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@torch.jit.script</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>optimized_function</span><span class=p>(</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># å¤æ‚çš„è®¡ç®—é€»è¾‘</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>result</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>jit</span><span class=o>.</span><span class=n>script</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šä¸æ˜¯æ‰€æœ‰æ“ä½œéƒ½èƒ½è¢«JITç¼–è¯‘ï¼Œéœ€è¦è¿›è¡Œå…¼å®¹æ€§æµ‹è¯•ã€‚</li></ul></li><li><p><strong>é«˜æ•ˆçš„æ•°æ®åŠ è½½</strong>ï¼š</p><ul><li>ä½¿ç”¨<code>num_workers</code>å‚æ•°æ¥å¹¶è¡ŒåŠ è½½æ•°æ®ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>dataloader</span> <span class=o>=</span> <span class=n>DataLoader</span><span class=p>(</span><span class=n>dataset</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>32</span><span class=p>,</span> <span class=n>num_workers</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>pin_memory</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šè¿‡å¤šçš„workerså¯èƒ½å¯¼è‡´å†…å­˜å‹åŠ›ï¼Œéœ€è¦æ ¹æ®ç³»ç»Ÿèµ„æºè¿›è¡Œè°ƒæ•´ã€‚</li></ul></li><li><p><strong>æ¨¡å‹å¹¶è¡ŒåŒ–</strong>ï¼š</p><ul><li>å¯¹äºå¤§å‹æ¨¡å‹ï¼Œè€ƒè™‘ä½¿ç”¨æ¨¡å‹å¹¶è¡ŒåŒ–æ¥åˆ†æ•£è®¡ç®—è´Ÿè½½ã€‚</li><li>æœ€ä½³å®è·µï¼šä½¿ç”¨<code>torch.nn.parallel.DistributedDataParallel</code>æ¥å®ç°ã€‚</li><li>æ³¨æ„äº‹é¡¹ï¼šéœ€è¦ä»”ç»†è®¾è®¡é€šä¿¡ç­–ç•¥ä»¥é¿å…æˆä¸ºç“¶é¢ˆã€‚</li></ul></li></ol><p><a name=åå‘ä¼ æ’­></a></p><h3 id=32-åå‘ä¼ æ’­>3.2 åå‘ä¼ æ’­</h3><p>åå‘ä¼ æ’­æ˜¯è®¡ç®—æ¢¯åº¦çš„è¿‡ç¨‹ï¼Œå¯¹å…¶è¿›è¡Œä¼˜åŒ–å¯ä»¥å¤§å¤§æé«˜è®­ç»ƒæ•ˆç‡ã€‚</p><ol><li><p><strong>æ¢¯åº¦ç´¯ç§¯</strong>ï¼š</p><ul><li>å®ç°ï¼šåœ¨å¤šä¸ªå°æ‰¹æ¬¡ä¸Šç´¯ç§¯æ¢¯åº¦ï¼Œç„¶åä¸€æ¬¡æ€§æ›´æ–°æ¨¡å‹ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>accumulation_steps</span> <span class=o>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>targets</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>dataloader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>targets</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=n>loss</span> <span class=o>/</span> <span class=n>accumulation_steps</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=n>accumulation_steps</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šéœ€è¦ç›¸åº”è°ƒæ•´å­¦ä¹ ç‡ã€‚</li></ul></li><li><p><strong>æ¢¯åº¦æ£€æŸ¥ç‚¹</strong>ï¼š</p><ul><li>å®ç°ï¼šåœ¨å‰å‘ä¼ æ’­æ—¶åªä¿å­˜å…³é”®èŠ‚ç‚¹çš„æ¿€æ´»ï¼Œå…¶ä»–æ¿€æ´»åœ¨åå‘ä¼ æ’­æ—¶é‡æ–°è®¡ç®—ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.utils.checkpoint</span> <span class=kn>import</span> <span class=n>checkpoint</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CheckpointedModule</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>checkpoint</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>submodule</span><span class=p>,</span> <span class=n>x</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šä¼šå¢åŠ è®¡ç®—æ—¶é—´ï¼Œä½†å¯ä»¥æ˜¾è‘—å‡å°‘å†…å­˜ä½¿ç”¨ã€‚</li></ul></li><li><p><strong>åå‘ä¼ æ’­ä¼˜åŒ–å™¨</strong>ï¼š</p><ul><li>ä½¿ç”¨é«˜æ•ˆçš„åå‘ä¼ æ’­ç®—æ³•ï¼Œå¦‚NVIDIAçš„Apexåº“ä¸­çš„ä¼˜åŒ–å™¨ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>apex</span> <span class=kn>import</span> <span class=n>amp</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span> <span class=o>=</span> <span class=n>amp</span><span class=o>.</span><span class=n>initialize</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>opt_level</span><span class=o>=</span><span class=s2>&#34;O1&#34;</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šéœ€è¦å®‰è£…é¢å¤–çš„åº“ï¼Œå¹¶å¯èƒ½éœ€è¦é€‚é…ä»£ç ã€‚</li></ul></li><li><p><strong>è‡ªå®šä¹‰åå‘ä¼ æ’­</strong>ï¼š</p><ul><li>å¯¹äºç‰¹å®šæ“ä½œï¼Œå¯ä»¥å®ç°è‡ªå®šä¹‰çš„åå‘ä¼ æ’­ä»¥æé«˜æ•ˆç‡ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>CustomFunction</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>autograd</span><span class=o>.</span><span class=n>Function</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nd>@staticmethod</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=n>ctx</span><span class=p>,</span> <span class=nb>input</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>.</span><span class=n>save_for_backward</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>custom_forward</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@staticmethod</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>backward</span><span class=p>(</span><span class=n>ctx</span><span class=p>,</span> <span class=n>grad_output</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>input</span><span class=p>,</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>.</span><span class=n>saved_tensors</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>custom_backward</span><span class=p>(</span><span class=n>grad_output</span><span class=p>,</span> <span class=nb>input</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šéœ€è¦ç¡®ä¿è‡ªå®šä¹‰æ“ä½œçš„æ•°å€¼ç¨³å®šæ€§å’Œæ­£ç¡®æ€§ã€‚</li></ul></li><li><p><strong>åˆ†å¸ƒå¼åå‘ä¼ æ’­</strong>ï¼š</p><ul><li>åœ¨å¤šGPUæˆ–å¤šæœºè®¾ç½®ä¸­ï¼Œä½¿ç”¨é«˜æ•ˆçš„æ¢¯åº¦èšåˆæ–¹æ³•ã€‚</li><li>æœ€ä½³å®è·µï¼šä½¿ç”¨NCCLåç«¯è¿›è¡Œæ¢¯åº¦åŒæ­¥ã€‚</li><li>æ³¨æ„äº‹é¡¹ï¼šéœ€è¦è€ƒè™‘ç½‘ç»œå¸¦å®½å’Œå»¶è¿Ÿçš„å½±å“ã€‚</li></ul></li></ol><p><a name=è‡ªåŠ¨å¾®åˆ†></a></p><h3 id=33-è‡ªåŠ¨å¾®åˆ†>3.3 è‡ªåŠ¨å¾®åˆ†</h3><p>è‡ªåŠ¨å¾®åˆ†æ˜¯ç°ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå¯¹å…¶è¿›è¡Œä¼˜åŒ–å¯ä»¥æé«˜æ•´ä½“è®­ç»ƒæ•ˆç‡ã€‚</p><ol><li><p><strong>ä½¿ç”¨PyTorchçš„autograd</strong>ï¼š</p><ul><li>PyTorchçš„autogradç³»ç»Ÿè‡ªåŠ¨å¤„ç†å¤§å¤šæ•°æ“ä½œçš„æ¢¯åº¦è®¡ç®—ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>y</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>grad</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šå¯¹äºå¤æ‚çš„è‡ªå®šä¹‰æ“ä½œï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨å®šä¹‰æ¢¯åº¦è®¡ç®—ã€‚</li></ul></li><li><p><strong>è‡ªå®šä¹‰autogradå‡½æ•°</strong>ï¼š</p><ul><li>å¯¹äºç‰¹å®šçš„å¤æ‚æ“ä½œï¼Œå¯ä»¥å®šä¹‰è‡ªå®šä¹‰çš„autogradå‡½æ•°ä»¥ä¼˜åŒ–æ€§èƒ½ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>CustomFunction</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>autograd</span><span class=o>.</span><span class=n>Function</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nd>@staticmethod</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=n>ctx</span><span class=p>,</span> <span class=nb>input</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>result</span> <span class=o>=</span> <span class=n>custom_forward</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>.</span><span class=n>save_for_backward</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>result</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@staticmethod</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>backward</span><span class=p>(</span><span class=n>ctx</span><span class=p>,</span> <span class=n>grad_output</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>input</span><span class=p>,</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>.</span><span class=n>saved_tensors</span>
</span></span><span class=line><span class=cl>        <span class=n>grad_input</span> <span class=o>=</span> <span class=n>custom_backward</span><span class=p>(</span><span class=n>grad_output</span><span class=p>,</span> <span class=nb>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>grad_input</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ä½¿ç”¨</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>CustomFunction</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=nb>input</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šç¡®ä¿è‡ªå®šä¹‰å‡½æ•°çš„å‰å‘å’Œåå‘ä¼ æ’­æ˜¯æ•°å€¼ç¨³å®šçš„ã€‚</li></ul></li><li><p><strong>æ¢¯åº¦æ£€æŸ¥</strong>ï¼š</p><ul><li>ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥æ¥éªŒè¯è‡ªåŠ¨å¾®åˆ†çš„æ­£ç¡®æ€§ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.autograd</span> <span class=kn>import</span> <span class=n>gradcheck</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>input</span> <span class=o>=</span> <span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>20</span><span class=p>,</span><span class=mi>20</span><span class=p>,</span><span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>double</span><span class=p>,</span><span class=n>requires_grad</span><span class=o>=</span><span class=kc>True</span><span class=p>),)</span>
</span></span><span class=line><span class=cl><span class=n>test</span> <span class=o>=</span> <span class=n>gradcheck</span><span class=p>(</span><span class=n>CustomFunction</span><span class=o>.</span><span class=n>apply</span><span class=p>,</span> <span class=nb>input</span><span class=p>,</span> <span class=n>eps</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>,</span> <span class=n>atol</span><span class=o>=</span><span class=mf>1e-4</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>test</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šæ¢¯åº¦æ£€æŸ¥å¯èƒ½ä¼šå¾ˆæ…¢ï¼Œé€šå¸¸åªåœ¨å¼€å‘å’Œè°ƒè¯•æ—¶ä½¿ç”¨ã€‚</li></ul></li><li><p><strong>é¿å…ä¸å¿…è¦çš„æ¢¯åº¦è®¡ç®—</strong>ï¼š</p><ul><li>ä½¿ç”¨<code>torch.no_grad()</code>ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¥é¿å…ä¸éœ€è¦æ¢¯åº¦çš„è®¡ç®—ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=c1># æ‰§è¡Œä¸éœ€è¦æ¢¯åº¦çš„æ“ä½œ</span>
</span></span><span class=line><span class=cl>    <span class=n>validation_loss</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>val_data</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šç¡®ä¿åœ¨æ­£ç¡®çš„åœ°æ–¹ä½¿ç”¨ï¼Œä¸è¦æ„å¤–åœ°é˜»æ­¢äº†å¿…è¦çš„æ¢¯åº¦è®¡ç®—ã€‚</li></ul></li><li><p><strong>åˆ©ç”¨è®¡ç®—å›¾ä¼˜åŒ–</strong>ï¼š</p><ul><li>PyTorchä¼šè‡ªåŠ¨ä¼˜åŒ–è®¡ç®—å›¾ï¼Œä½†äº†è§£è¿™äº›ä¼˜åŒ–å¯ä»¥å¸®åŠ©ä½ å†™å‡ºæ›´é«˜æ•ˆçš„ä»£ç ã€‚</li><li>æœ€ä½³å®è·µï¼šé¿å…åˆ›å»ºä¸å¿…è¦çš„ä¸­é—´å¼ é‡ï¼Œåˆ©ç”¨åŸä½æ“ä½œã€‚</li><li>æ³¨æ„äº‹é¡¹ï¼šæŸäº›ä¼˜åŒ–å¯èƒ½ä¼šå½±å“æ•°å€¼ç²¾åº¦ï¼Œéœ€è¦åœ¨æ•ˆç‡å’Œç²¾åº¦ä¹‹é—´æƒè¡¡ã€‚</li></ul></li></ol><p><a name=æ¢¯åº¦æ›´æ–°></a></p><h3 id=34-æ¢¯åº¦æ›´æ–°>3.4 æ¢¯åº¦æ›´æ–°</h3><p>æ¢¯åº¦æ›´æ–°æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­çš„å…³é”®æ­¥éª¤ï¼Œå¯¹å…¶è¿›è¡Œä¼˜åŒ–å¯ä»¥æé«˜æ”¶æ•›é€Ÿåº¦å’Œæ¨¡å‹æ€§èƒ½ã€‚</p><ol><li><p><strong>å®ç°Adamä¼˜åŒ–å™¨</strong>ï¼š</p><ul><li>Adamæ˜¯ä¸€ç§å¹¿æ³›ä½¿ç”¨çš„ä¼˜åŒ–ç®—æ³•ï¼Œç»“åˆäº†åŠ¨é‡å’Œè‡ªé€‚åº”å­¦ä¹ ç‡ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>Adam</span><span class=p>(</span><span class=n>Optimizer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>params</span><span class=p>,</span> <span class=n>lr</span><span class=o>=</span><span class=mf>1e-3</span><span class=p>,</span> <span class=n>betas</span><span class=o>=</span><span class=p>(</span><span class=mf>0.9</span><span class=p>,</span> <span class=mf>0.999</span><span class=p>),</span> <span class=n>eps</span><span class=o>=</span><span class=mf>1e-8</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>defaults</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(</span><span class=n>lr</span><span class=o>=</span><span class=n>lr</span><span class=p>,</span> <span class=n>betas</span><span class=o>=</span><span class=n>betas</span><span class=p>,</span> <span class=n>eps</span><span class=o>=</span><span class=n>eps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>Adam</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=n>params</span><span class=p>,</span> <span class=n>defaults</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>step</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>group</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>param_groups</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>group</span><span class=p>[</span><span class=s1>&#39;params&#39;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>p</span><span class=o>.</span><span class=n>grad</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>continue</span>
</span></span><span class=line><span class=cl>                <span class=n>grad</span> <span class=o>=</span> <span class=n>p</span><span class=o>.</span><span class=n>grad</span><span class=o>.</span><span class=n>data</span>
</span></span><span class=line><span class=cl>                <span class=n>state</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>state</span><span class=p>[</span><span class=n>p</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=c1># åˆå§‹åŒ–çŠ¶æ€</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>state</span><span class=p>)</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>state</span><span class=p>[</span><span class=s1>&#39;step&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>                    <span class=n>state</span><span class=p>[</span><span class=s1>&#39;exp_avg&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>state</span><span class=p>[</span><span class=s1>&#39;exp_avg_sq&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=n>exp_avg</span><span class=p>,</span> <span class=n>exp_avg_sq</span> <span class=o>=</span> <span class=n>state</span><span class=p>[</span><span class=s1>&#39;exp_avg&#39;</span><span class=p>],</span> <span class=n>state</span><span class=p>[</span><span class=s1>&#39;exp_avg_sq&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=n>beta1</span><span class=p>,</span> <span class=n>beta2</span> <span class=o>=</span> <span class=n>group</span><span class=p>[</span><span class=s1>&#39;betas&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=n>state</span><span class=p>[</span><span class=s1>&#39;step&#39;</span><span class=p>]</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=c1># æ›´æ–°ç§»åŠ¨å¹³å‡</span>
</span></span><span class=line><span class=cl>                <span class=n>exp_avg</span><span class=o>.</span><span class=n>mul_</span><span class=p>(</span><span class=n>beta1</span><span class=p>)</span><span class=o>.</span><span class=n>add_</span><span class=p>(</span><span class=n>grad</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mi>1</span> <span class=o>-</span> <span class=n>beta1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>exp_avg_sq</span><span class=o>.</span><span class=n>mul_</span><span class=p>(</span><span class=n>beta2</span><span class=p>)</span><span class=o>.</span><span class=n>addcmul_</span><span class=p>(</span><span class=n>grad</span><span class=p>,</span> <span class=n>grad</span><span class=p>,</span> <span class=n>value</span><span class=o>=</span><span class=mi>1</span> <span class=o>-</span> <span class=n>beta2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=c1># è®¡ç®—åå·®ä¿®æ­£</span>
</span></span><span class=line><span class=cl>                <span class=n>bias_correction1</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>beta1</span> <span class=o>**</span> <span class=n>state</span><span class=p>[</span><span class=s1>&#39;step&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=n>bias_correction2</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>beta2</span> <span class=o>**</span> <span class=n>state</span><span class=p>[</span><span class=s1>&#39;step&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=c1># åº”ç”¨æ›´æ–°</span>
</span></span><span class=line><span class=cl>                <span class=n>step_size</span> <span class=o>=</span> <span class=n>group</span><span class=p>[</span><span class=s1>&#39;lr&#39;</span><span class=p>]</span> <span class=o>*</span> <span class=n>math</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>bias_correction2</span><span class=p>)</span> <span class=o>/</span> <span class=n>bias_correction1</span>
</span></span><span class=line><span class=cl>                <span class=n>p</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>addcdiv_</span><span class=p>(</span><span class=n>exp_avg</span><span class=p>,</span> <span class=n>exp_avg_sq</span><span class=o>.</span><span class=n>sqrt</span><span class=p>()</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>group</span><span class=p>[</span><span class=s1>&#39;eps&#39;</span><span class=p>]),</span> <span class=n>value</span><span class=o>=-</span><span class=n>step_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ä½¿ç”¨</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šAdamå¯èƒ½ä¸é€‚ç”¨äºæ‰€æœ‰æƒ…å†µï¼Œæœ‰æ—¶éœ€è¦å°è¯•å…¶ä»–ä¼˜åŒ–å™¨å¦‚SGDæˆ–RMSpropã€‚</li></ul></li><li><p><strong>æ¢¯åº¦è£å‰ª</strong>ï¼š</p><ul><li>æ¢¯åº¦è£å‰ªå¯ä»¥é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>clip_grad_norm_</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>max_norm</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šè£å‰ªé˜ˆå€¼éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡è°ƒæ•´ã€‚</li></ul></li><li><p><strong>å­¦ä¹ ç‡è°ƒåº¦</strong>ï¼š</p><ul><li>åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡å¯ä»¥æé«˜è®­ç»ƒæ•ˆæœã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.optim.lr_scheduler</span> <span class=kn>import</span> <span class=n>StepLR</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>scheduler</span> <span class=o>=</span> <span class=n>StepLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>step_size</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>100</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>train</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šä¸åŒçš„ä»»åŠ¡å¯èƒ½éœ€è¦ä¸åŒçš„å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥ã€‚</li></ul></li><li><p><strong>æƒé‡è¡°å‡</strong>ï¼š</p><ul><li>æƒé‡è¡°å‡ï¼ˆL2æ­£åˆ™åŒ–ï¼‰å¯ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>,</span> <span class=n>weight_decay</span><span class=o>=</span><span class=mf>1e-5</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šæƒé‡è¡°å‡ç³»æ•°éœ€è¦æ ¹æ®æ¨¡å‹å’Œæ•°æ®é›†è°ƒæ•´ã€‚</li></ul></li><li><p><strong>æ¢¯åº¦ç´¯ç§¯</strong>ï¼š</p><ul><li>å¯¹äºå¤§å‹æ¨¡å‹æˆ–å°æ‰¹é‡å¤§å°ï¼Œæ¢¯åº¦ç´¯ç§¯å¯ä»¥æ¨¡æ‹Ÿæ›´å¤§çš„æ‰¹é‡å¤§å°ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>accumulation_steps</span> <span class=o>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>dataloader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=n>loss</span> <span class=o>/</span> <span class=n>accumulation_steps</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=n>accumulation_steps</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šéœ€è¦ç›¸åº”è°ƒæ•´å­¦ä¹ ç‡ã€‚</li></ul></li></ol><p><a name=ç³»ç»Ÿçº§ä¼˜åŒ–></a></p><h2 id=4-ç³»ç»Ÿçº§ä¼˜åŒ–>4. ç³»ç»Ÿçº§ä¼˜åŒ–</h2><p>ç³»ç»Ÿçº§ä¼˜åŒ–æ¶‰åŠåˆ°ç¡¬ä»¶èµ„æºçš„é«˜æ•ˆåˆ©ç”¨ï¼ŒåŒ…æ‹¬å†…å­˜ç®¡ç†ã€CUDAåç«¯ä¼˜åŒ–ã€ä»¥åŠå•æœºå¤šå¡å’Œå¤šæœºå¤šå¡çš„å¹¶è¡Œè®­ç»ƒç­–ç•¥ã€‚</p><p><a name=å†…å­˜ç®¡ç†></a></p><h3 id=41-å†…å­˜ç®¡ç†>4.1 å†…å­˜ç®¡ç†</h3><p>æœ‰æ•ˆçš„å†…å­˜ç®¡ç†å¯¹äºè®­ç»ƒå¤§å‹æ¨¡å‹è‡³å…³é‡è¦ï¼Œå¯ä»¥æ˜¾è‘—æé«˜è®­ç»ƒæ•ˆç‡å¹¶å…è®¸å¤„ç†æ›´å¤§çš„æ¨¡å‹ã€‚</p><ol><li><p><strong>æ¢¯åº¦æ£€æŸ¥ç‚¹</strong>ï¼š</p><ul><li>åŸç†ï¼šåœ¨å‰å‘ä¼ æ’­æ—¶åªä¿å­˜éƒ¨åˆ†ä¸­é—´æ¿€æ´»ï¼Œå…¶ä»–æ¿€æ´»åœ¨åå‘ä¼ æ’­æ—¶é‡æ–°è®¡ç®—ã€‚</li><li>å®ç°ï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.utils.checkpoint</span> <span class=kn>import</span> <span class=n>checkpoint</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CheckpointedModule</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>checkpoint</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>submodule</span><span class=p>,</span> <span class=n>x</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æœ€ä½³å®è·µï¼š<ul><li>é€‰æ‹©åˆé€‚çš„æ£€æŸ¥ç‚¹é—´éš”ï¼Œå¹³è¡¡å†…å­˜ä½¿ç”¨å’Œè®¡ç®—å¼€é”€ã€‚</li><li>å¯¹è®¡ç®—å¯†é›†ä½†å†…å­˜å ç”¨è¾ƒå°çš„å±‚åº”ç”¨æ£€æŸ¥ç‚¹ã€‚</li></ul></li><li>æ³¨æ„äº‹é¡¹ï¼šä¼šå¢åŠ è®¡ç®—æ—¶é—´ï¼Œéœ€è¦æƒè¡¡å†…å­˜èŠ‚çœå’Œé¢å¤–è®¡ç®—ã€‚</li></ul></li><li><p><strong>å†…å­˜ç¢ç‰‡ç®¡ç†</strong>ï¼š</p><ul><li>ä½¿ç”¨PyTorchçš„å†…å­˜åˆ†é…å™¨æ¥å‡å°‘å†…å­˜ç¢ç‰‡ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>cudnn</span><span class=o>.</span><span class=n>benchmark</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>empty_cache</span><span class=p>()</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šå®šæœŸè°ƒç”¨<code>empty_cache()</code>å¯èƒ½ä¼šå½±å“æ€§èƒ½ï¼Œéœ€è¦è°¨æ…ä½¿ç”¨ã€‚</li></ul></li><li><p><strong>æ¢¯åº¦ç´¯ç§¯</strong>ï¼š</p><ul><li>å®ç°å¤§æ‰¹é‡è®­ç»ƒè€Œä¸å¢åŠ å†…å­˜ä½¿ç”¨ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>accumulation_steps</span> <span class=o>=</span> <span class=mi>4</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>dataloader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span> <span class=o>/</span> <span class=n>accumulation_steps</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=n>accumulation_steps</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šéœ€è¦ç›¸åº”è°ƒæ•´å­¦ä¹ ç‡å’Œå…¶ä»–è¶…å‚æ•°ã€‚</li></ul></li><li><p><strong>æ··åˆç²¾åº¦è®­ç»ƒ</strong>ï¼š</p><ul><li>ä½¿ç”¨FP16å‡å°‘å†…å­˜ä½¿ç”¨å’Œæé«˜è®¡ç®—é€Ÿåº¦ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.cuda.amp</span> <span class=kn>import</span> <span class=n>autocast</span><span class=p>,</span> <span class=n>GradScaler</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>scaler</span> <span class=o>=</span> <span class=n>GradScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>inputs</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>dataloader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>autocast</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=o>.</span><span class=n>scale</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>optimizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=o>.</span><span class=n>update</span><span class=p>()</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šæŸäº›æ“ä½œå¯èƒ½éœ€è¦ä¿æŒFP32ç²¾åº¦ä»¥ä¿è¯æ•°å€¼ç¨³å®šæ€§ã€‚</li></ul></li><li><p><strong>ä¼˜åŒ–å¼ é‡å­˜å‚¨å’Œé‡ç”¨</strong>ï¼š</p><ul><li>é‡ç”¨å¼ é‡ä»¥å‡å°‘å†…å­˜åˆ†é…å’Œé‡Šæ”¾çš„å¼€é”€ã€‚</li><li>æœ€ä½³å®è·µï¼š<div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># é¢„åˆ†é…ç¼“å†²åŒº</span>
</span></span><span class=line><span class=cl><span class=n>buffer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>empty</span><span class=p>(</span><span class=mi>1000</span><span class=p>,</span> <span class=mi>1000</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>iterations</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># åœ¨é¢„åˆ†é…çš„ç¼“å†²åŒºä¸Šæ‰§è¡Œæ“ä½œ</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=n>some_operation</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=n>out</span><span class=o>=</span><span class=n>buffer</span><span class=p>)</span>
</span></span></code></pre></div></li><li>æ³¨æ„äº‹é¡¹ï¼šç¡®ä¿é‡ç”¨çš„å¼ é‡å¤§å°é€‚åˆæ‰€æœ‰æ“ä½œï¼Œå¦åˆ™å¯èƒ½å¯¼è‡´æ„å¤–çš„é‡æ–°åˆ†é…ã€‚</li></ul></li></ol><p><a name=cudaåç«¯></a></p><h3 id=42-cudaåç«¯>4.2 CUDAåç«¯</h3><p>CUDAåç«¯ä¼˜åŒ–æ˜¯æé«˜GPUåˆ©ç”¨ç‡å’Œè®¡ç®—æ•ˆç‡çš„å…³é”®ã€‚</p><ol><li><strong>åˆ©ç”¨CUDAæ ¸å¿ƒåŠ é€Ÿè®¡ç®—</strong>ï¼š<ul><li>ä½¿ç”¨</li></ul></li></ol></section><footer class=article-footer><section class=article-tags><a href=/zh-cn/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/>ç¥ç»ç½‘ç»œ</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>ç›¸å…³æ–‡ç« </h2><div class=related-content><div class="flex article-list--tile"><article><a href=/zh-cn/p/mnist/><div class=article-details><h2 class=article-title>Mnist</h2></div></a></article><article><a href=/zh-cn/p/lanntai-ai-for-human/><div class=article-details><h2 class=article-title>lanntai AI for human</h2></div></a></article></div></div></aside><div id=gitalk-container></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css><script src=https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js></script><script src=https://cdn.jsdelivr.net/npm/blueimp-md5@2.18.0/js/md5.min.js></script><script>const gitalk=new Gitalk({clientID:"Ov23liqc7SD1bN7OvCI6",clientSecret:"7b0ed5cd67a344de02c2efded9da2dfb8ac14783",repo:"tannal.github.io",owner:"tannal",admin:["tannal"],distractionFreeMode:!1,id:md5(location.pathname),proxy:null});(function(){const e=["localhost","127.0.0.1"],t=window.location.hostname;if(e.includes(t)){document.getElementById("gitalk-container").innerHTML="Gitalk comments not available by default when the website is previewed locally.";return}gitalk.render("gitalk-container")})()</script><footer class=site-footer><section class=copyright>&copy;
2024 -
2025 è°­ç›Ÿ</section><section class=powerby>ä½¿ç”¨ <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> æ„å»º<br>ä¸»é¢˜ <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.32.0>Stack</a></b> ç”± <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> è®¾è®¡</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.c922af694cc257bf1ecc41c0dd7b0430f9114ec280ccf67cd2c6ad55f5316c4e.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>